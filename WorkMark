2017-7-5

Done:
    1.添加文件记录面板UIRecording并添加对其的调用。

2017-7-4

Done:
    1.添加相机控制面板UICameraCtrl并添加对UICameraCtrl的调用。

2017-7-3

Done:
    1.添加自定义控件UICameraInfo，用来显示相机的参数信息。
    2.QDockWidget是派生自QWidget的，在QMainWindow中可以通过addDockWidget添加QDockWidget，但是在QWidget中不可以，另外，QDialog中也没有addDockWidget函数。看来QDockWidget只能直接添加在主界面中，之前所想的把QDockWidget先封装在一个QWidget控件中，再把QWidget添加至主界面的想法是行不通的。
    3.添加对UICameraInfo的调用，在主界面中添加cameraInfoDockWidget，并提升为UICameraInfo。
    4.添加相机参数信息显示。同时，在MainWindow中，将函数分为UI部分和数据部分，UI部分专门用来接受控件的响应和对控件进行设置，数据部分用来处理数据部分，尽量做到UI部分只操作UI，其他处理放在数据部分做。

2017-6-30

Done:
    1.因为VS依赖库的原因，把FFMPEG的功能先屏蔽掉。
    2.因为依赖库的原因，去掉保存为FITS格式的功能。看来在Qt中使用VS编译的dll还是要非常小心，特别是还要支持跨平台，能用源码尽量用源码，尽量不要去用别人已经编译好的库，以免产生连锁依赖。
    3.将保存文件的支持格式写入ini配置文件，以后尽量(1)要把一些有可能改动的地方写入配置文件，以便不改代码就可以改动，(2)界面中除了控件，尽量把其他的逻辑都不要放在界面上，以便于更换界面。

Todo:
    1.UI设计
    (1)信息显示：已经发现的相机及参数
    (2)相机控制
    (3)直方图显示
    (4)数据记录

Memo:
    1.经过这么长时间对AVI的折腾，RAW8的视频记录最终也没有弄好。经过测试，RAW8播放不出来或全黑色的现象在OACapture中也出现了同样的遭遇，使用QQ影音、暴风影音、完美解码、KMPlayer都播放不出来，但用VLC、AutoStakkert可以播放出来，一方面可能与播放器的解码器是否支持有关系，另一方面，在使用FFmpeg写AVI文件的时候，估计也是有一些参数没有做好，因为使用SharpCap记录的RAW8视频，在上述所有播放器上都可以播放出来，这或许可以说明，上述播放不出来的播放器不一定是不支持RAW8的AVI，而是可能对参数要求比较严格，当检测到参数不符合时，就无法正常播放，而上述能播放出来的播放器，可能容错性做得好一些。后面不打算使用FFMPEG了，准备自己按照avi的格式自己写文件。

2017-6-29

Done:
	1.在虚拟机中安装干净的win7系统，测试程序的依赖项，后来发现，由于使用了VS编译的dll，导致出现了大量的VS依赖项及对.net的依赖。这么看来，在程序中不能随便使用VS编译的dll，要使用也要降低对.net的依赖，如果需要使用第三方库，尽量使用源码。
	2.编译出了在加入FFmpeg之前的5月15日SVN117版本，添加了四个dll(vcruntime140.dll、libwinpthread-1.dll、libstdc++-6.dll、libgcc_s_dw2-1.dll)之后，可以在干净的win7系统中跑起来。

Todo:
    1.在虚拟机中测试程序依赖项

2017-6-28

Done:
    1.网上很多生成avi文件的代码，但基本上都使用了Windows的vfw库，无法在OSX和Linux上移植，因此，都不可用。
    2.从GitHub上找的代码，出去不符合要求的和编译不出来的，只有generate_avi_example可用，但是generate_avi_example是先生成jpg文件再将jpg转成avi。

Memo:
    1.AVI文件采用的是RIFF文件结构方式，RIFF（Resource Interchange File Format，资源互换文件格式）是微软公司定义的一种用于管理windows环境中多媒体数据的文件格式。构造RIFF文件的基本单元叫做数据块（Chunk），每个数据块包含3个部分，(1)4字节的数据块标记（或者叫做数据块的ID），(2)数据块的大小，(3)数据。
    2.整个RIFF文件可以看成一个数据块，其数据块ID为RIFF，称为RIFF块。一个RIFF文件中只允许存在一个RIFF块。RIFF块中包含一系列 的子块，其中有一种字块的ID为"LIST"，称为LIST，LIST块中可以再包含一系列的子块，但除了LIST块外的其他所有的子块都不能再包含子块。
    3.RIFF和LIST块分别比普通的数据块多一个被称为形式类型（Form Type）和列表类型（List Type）的数据域，其组成如下：(1)4字节的数据块标记（Chunk ID）、(2)数据块的大小、(3)4字节的形式类型或者列表类型、(4)数据。
    4.AVI的RIFF块的形式类型是AVI，它包含3个子块，如下所述：(1)信息块，一个ID为"hdrl"的LIST块，定义AVI文件的数据格式。(2)数据块，一个ID为 "movi"的LIST块，包含AVI的音视频序列数据。(3)索引块，ID为"idxl"的子块，定义"movi"LIST块的索引数据，是可选块。
    5.DIB设备无关位图文件，这是一种文件格式，是为了保证由某个应用程序创建的位图图形可以被其它应用程序装载或显示。 DIB的与设备无关性主要体现在以下两个方面：DIB的颜色模式与设备无关。例如，一个256色的DIB即可以在真彩色显示模式下使用，也可以在16色模式下使用。256色以下（包括256色）的DIB拥有自己的颜色表，像素的颜色独立于系统调色板。由于DIB不依赖于具体设备，因此可以用来永久性地保存图象。DIB一般是以*.BMP文件的形式保存在磁盘中的，有时也会保存在*.DIB文件中。运行在不同输出设备下的应用程序可以通过DIB来交换图象。
    6.AVI的音频视频帧的开头:Avi中视频音频交叉存放，每一帧视频都有一个视频帧头：30 30 64 63（这是二进制编码，字符是00dc），然后接着就是四个字节的帧长度，例如00 00 10 00，再往下就是帧的内容。Avi的音频也有一个音频头：30 31 77 62（01wb），接着就是音频的长度，例如00 10 00 00，就是4096字节，接着就是音频的内容了。
    7.当AVI文件中包含有多个流的时候，数据块与数据块之间如何来区别呢？于是数据块使用了一个四字符码来表征它的类型，这个四字符码由2个字节的类型码和2个字节的流编号组成。 标准的类型码定义如下： 1. ‘db’（非压缩视频帧）、 2. ‘dc’（压缩视频帧）、 3. ‘pc’（改用新的调色板）、 4. ‘wb’（音缩视频）。  比如第一个流（Stream 0）是音频，则表征音频数据块的四字符码为‘00wb’；第二个流（Stream 1）是视频，则表征视频数据块的四字符码为‘00db’或‘00dc’。对于视频数据来说，在AVI数据序列中间还可以定义一个新的调色板，每个改变的调色板数据块用‘xxpc’来表征，新的调色板使用一个数据结构AVIPALCHANGE来定义。（注意：如果一个流的调色办中途可能改变，则应在这个流格式的描述中，也就是AVISTREAMHEADER结构的dwFlags中包含一个AVISF_VIDEO_PALCHANGES标记。）另外，文字流数据块可以使用随意的类型码表征。

2017-6-27

Memo:
    1.8位数据的视频文件用QQ影音、暴风影音、完美解码、KMPlayer都播放不出来，用VLC、AutoStakkert可以播放出来。
    2.OACapture记录的视频文件和我们记录的情况大致相同，有一点不同的是OACapture记录的24位数据的文件用AutoStakkert播放不出来。
    3.SharpCap记录的8位数据视频从文件大小和文件头信息来看，确实是8位的，用上述几个软件都可以播放，比较文件头没看出有什么差别，从安装包的dll中也没看出来他是用什么做的。
    4.周扬帮着问了SharpCap作者使用的方法，回答说是使用的DirectShow中的方法做的，其他的不愿多说。

Done:
    1.确实，SharpCap记录下的8位视频是各种播放器都可以播出来的，而且确实是8位的，大小刚好是24的三分之一。从其安装文件夹中没看出来他是用什么方法做的。
    2.PlanetaryImager在utuntu下编译通过，编译完成后进行了测试，更改界面中的某个字符串，重新make all和make install，新生成的程序中界面中字符串确实发生了改变。
    3.从GitHub上找avi文件的代码，generate_avi_example和libgwavi看上去可以用。

2016-6-26

Done:
    1.终于在Ubuntu下编译OACapture通过，见《ubuntu下编译OACapture》，编译完成之后，进行了测试，更改界面中的某个字符串，重新进行make和make install，新生成的程序中界面中字符串值确实有了改变。

2017-6-16

Todo:
    1.继续梳理昨天的流程

2017-6-15

Done:
    1.录制视频文件添加对RAW16数据格式的支持，RAW16可以正确显示，但是RAW8显示的还是一片黑色。
    2.没有找到具体原因，不知道RAW8为什么显示不出来，AV_PIX_FMT_GRAY8和AV_PIX_FMT_PAL8都试过了，都没用。可以肯定，不是数据的问题，做了个小测试，其他不变，将bits_per_coded_sample=8改为bits_per_coded_sample=16，图像是可以显示出来的，不过由于数据本身是RAW8的，所以显示出来的图像在宽度方向上被挤扁了，有效图像宽度变为原来的1/2，但是图像数据看上去是对的。
    3.搞不定，貌似把bits_per_coded_sample设置成8之后图像显示的就是一片黑，但确确实实就应该是8啊。还有一点就是，如果视频文件是一片黑的那种，在Windows窗口中也显示不出来文件的信息，对于正常的文件，鼠标点上去之后，可以显示出来视频的高度、宽度、时长等，但是那种不正常的文件，就显示不出来，可能是在写文件头的时候出问题了吧。
    4.由于怀疑bits_per_coded_sample设置不正确导致的一片黑色，从网上搜了个函数来计算bits_per_coded_sample，测试后发现，这么设置似乎也没错(http://cache.baiducontent.com/c?m=9f65cb4a8c8507ed4fece7631046893b4c4380146d96864968d4e414c42246041d6cf4bc53221207d0d82f2747f41802bded602571507be9dad58f4adabd902b298f33712d5cd04e42885feedc4755d627e44de8df5bb0fae733e3b9d5a7c855239b0e532dd6e78a2a1713be78f16470b0f9db1642&p=c074c54ad5c242ec0be2962449059d&newp=85769a4783934eac59eecd295a5080231610db2151d7da136b82c825d7331b001c3bbfb42324100fd9c178610baa4258eff43075330825a3dda5c91d9fb4c57479dd&user=baidu&fm=sc&query=bits%5Fper%5Fcoded%5Fsample+site%3Ablog%2Ecsdn%2Enet&qid=a474d9ca0001360e&p1=2)
    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(st->codec->pix_fmt); 
    int bits_per_coded_sample = av_get_bits_per_pixel(desc); 
    5.对照雷神总结的流程，再查一下，看看能不能把这个问题解决了(http://blog.csdn.net/leixiaohua1020/article/details/25430425、http://blog.csdn.net/leixiaohua1020/article/details/44226355、http://blog.csdn.net/leixiaohua1020/article/details/44116215)
    6.根据雷神的文章(http://blog.csdn.net/leixiaohua1020/article/details/11693997)，AVFrame和AVPacket都是用来存储一帧数据的，AVPacket存储解码前的数据，AVFrame存储解码后的数据，对于编码来说，那AVFrame应该就是存储编码前的数据，AVPacket应该就是存储编码后的数据。雷神提供的流程图中，多出的一步是avcodec_encode_video2()，用于编码一帧视频。即，将AVFrame编码为AVPacket(http://blog.csdn.net/leixiaohua1020/article/details/25430425、http://blog.csdn.net/leixiaohua1020/article/details/44226355)，本程序中没有使用AVFrame，直接用的AVPacket，不知道显示黑色是否与此有关。

2017-6-14

Done:
    1.仅仅找到一种可以把RGB转换为YUV的方法(使用sws_scale函数)，但仍然没能解决编码的问题，录制出来的图像质量仍然很差。

2017-6-13

Memo:
    1.在《YUV视频序列编码为视频》这篇文章中提到，“大多数的视频格式好像只支持YUV格式的视频帧AVFrame，我试图直接把RGB的视频序列直接编码到视频这条路好像走不通，都需要把RGB的视频帧再转成YUV视频帧才行”。(http://blog.csdn.net/yang_xian521/article/details/7698742)

Todo:
    1.研究FFMpeg数据格式的问题，AVI的不要压缩---------------------------------------------------------------------------
    2.UI布局------------------------------------------------------------------------------------------------------------
    3.发布内部测试版本--------------------------------------------------------------------------------------------------

2017-6-12

Done:
    1.查找RAW16时崩溃的原因
       先看QImage的构造函数
       QImage::QImage(uchar *data, int width, int height, Format format, QImageCleanupFunction cleanupFunction = Q_NULLPTR, void *cleanupInfo = Q_NULLPTR)
       在说明文档中，有这样一段话：
       The buffer must remain valid throughout the life of the QImage and all copies that have not been modified or otherwise detached from the original buffer. The image does not delete the buffer at destruction. You can provide a function pointer cleanupFunction along with an extra pointer cleanupInfo that will be called when the last copy is destroyed.
       也就是说，数据buffer不是在QImage构造完之后就没用了，而是其内存将与QImage一直关联着，直到QImage的生命周期结束。而且，QImage生命结束后还不会主动去释放buffer的内存，要么自己手动去释放，要么通过自己定义一个指向cleanupFunction的函数指针去释放。
       在本程序中，QImage后续还在使用的时候，pNewDataBuff就已经被释放了，并且还被置成了Q_NULLPTR，所以后面在使用的QImage的时候就崩溃了。如果这里仅仅是delete而没有被置为Q_NULLPTR，后面可能不会崩溃，但图像显示是错的。
    2.RAW16记录不下来FIT文件是因为FitsFileRW中没有添加对16bitpix数据格式的支持，已经添加，可以记录数据了。
    3.RAW8时记录视频文件有内存泄漏可能是因为从RAW8转为RGB24时花的时间长，导致数据堆积。
    4.还有一个原因是RGB转YUV420时时间也长
    5.RAW8记录视频时内存泄漏的原因是①从RAW向RGB24转换时用的时间太长，②从RGB24向YUV420转换时用的时间太长，虽然无论是对于RAW8、RAW16还是RGB24，步骤②都是必须的，但是RGB24不需要步骤①，所以，在RGB24格式下，没有看到明显的内存泄漏，而在RAW8和RAW16格式，①和②的时间都很长，这就导致m_videoToRecordList会在长时间内得不到解锁，因此，当有新数据到来时，会一直等着解锁，也就造成了内存泄漏。由于后面的工作还要对FFMpegVideoRecorder进行改造，因此，②带来的问题暂时先不去处理，针对①带来的问题，目前的解决方案是  为m_videoToRecordList增加了个副本m_videoToRecordCopyList，每次处理时将m_videoToRecordList中的数据拷贝到m_videoToRecordCopyList中后就解锁，这样可以避免在调用saveAsVideo时m_videoToRecordList被锁时间太长。通过这种处理，内存泄漏的问题暂时得以解决。

Todo:
    1.测试时发现颜色空间调成RAW16时会崩溃
    2.RAW16记录不下来FIT文件
    3.RAW8时记录视频文件有内存泄漏

2016-6-9

Todo:
    1.需要注意，现在图像数据格式在DataProc中就已经做了32位对齐处理，所有下游类在使用时需要注意，以免受影响--------------

Done:
    1.基本完成了对数据传输策略的改造，现在DataProcThread不再对数据进行软件ROI、转换成RGB888格式的操作，而仅仅是对图像数据做了32位对齐处理，就将图像传递给了下游类，下游各使用数据的类(包括图像显示类ImageShowInQt、数据记录线程类DataProcThread和直方图显示类HistogramShow)得到数据后，需根据图像的格式进行相应地处理。
    2.改造完成后在测试时发现，记录静态图像时，第一张可以记录下来，记录第二张时就会出现问题。
    3.修复bug：现象：记录照片时，记录完第一张，再记录第二张时，就记录不下来了，记录按钮一直是灰色。修复：原因是m_bIsThreadStopped初始化时被设置为false，导致记录第一张照片时就触动了while (!m_bIsThreadStopped)循环，这个循环一直退不出来，所以就卡在这里了。
    4.又发现另外一个问题，记录视频文件时，无论是mp4还是avi，都会崩溃。
    5.现在知道记录视频崩溃是因为向videoRecorderBegin函数中传递的imgType参数不对引起的，之前全部转换成RGB格式，所以这里默认就是RGB，现在有了各种格式，但是视频记录类忘记了做相应变化，因此就出现了问题。
    6.FFMpegVideoRecorder的fill_yuv_image函数中，对数据格式g_video_data_format的判断，由原来的使用数字改为使用枚举。VideoRecorder::videoRecorderBegin中传入的数据格式的参数，由原来的数字改为枚举。在DataRecordThread::saveAsVideo中，会将数据统一转换成RGB格式的数据，调用VideoRecorder::videoRecorderBegin时，数据格式固定传入IMG_TYPE_RGB，目前还没有想好数据转换在哪里做比较合适，暂时先这么做。

2017-6-8

Memo:
    1.修改数据传输策略，之前订的策略是，无论什么格式的数据，一律转换成RGB24格式的，现在看来还不行，因为后续环节对数据的需求各种各样，RGB24不能满足需求，还是需要传递数据原来的格式，在需要转的地方，哪儿需要就在哪儿转。

Todo:
    1.修改数据传输策略

Done:
    1.writeFitsFileTest可以运行，结果正确。
    2.writeFitsFileTest调用 writeFitsFile，运行正常
    3.writeFitsFile中添加addkey运行正常
    4.在 writeFitsFileTest函数中测试addKey，运行正常
    5.在 writeFitsFileTest 中调用 addKey的重载函数，运行也正常
    6.把之前一直崩溃的QMap<QString, QString> m_mapKeyDesc也放开，测试之后也是正常，现在看来，在writeFitsFileTest函数中，之前所写的代码运行都是正常的
    7.改成从外面传参数，又出现了各种问题，看来从类内部传参数都是正常的，一旦从类外面传参数，就会有问题，总结如下：1.文件名一开始用的是const QString &，传进去之后发现为空，后来改为QString；2、数据一开始用的是const valarray &，但传进去之后数据就没了，去掉&之后也不行，后来改为传入const char *，在类内部再将char *转为valarray；3、用于调用的Test类中，FitsFileRW.h中的各变量声明也要和原来的相一致，原本以为在Test类中，那些私有变量没有用，可以删掉，可是删掉之后程序就会崩溃。
    8.添加 FitsFileRW动态库用于记录FITS文件，但由于FITS只能存灰度图像，而当前设计的数据流程传过来的是RGB图像，所以代码暂时还无法测试。后面还需要修改数据传输流程。
    9.对CCfits的封装位于：E:\MyProjects\Qt5.8.0_minGW530\FitsFileRW\FitsFileRW，对封装之后的FitsFileRW的调用位于：E:\MyProjects\Qt5.8.0_minGW530\FitsFileRWTest


2017-6-7

Done:
    1.昨天使用源码的方式调用CCfits已经成功，今天打算把CCfits再封装一下，封装成动态库，再由主程序调用，主要是不想把那么多的头文件和实现文件都加到主工程中去，没想到这么小的一个封装，竟然折腾了一天都没做好，封装之后各种问题频出，而且崩溃都是出在CCfits内部代码中，实在看不出是什么原因造成的。看来今天是搞不定了，但问题总要解决，只要一点一点调试了。今天是高考，本来智力应该达到巅峰的，却连小小的问题都解决不了，看来确实已经过了智力巅峰的阶段，开始走下坡路了。

2017-6-6

Done:
    1.测试CCFits小程序，解决undefined reference to 的问题
    2.解决“cmd.exe”已退出，代码为 3”的问题
    3.在VS下测，CCFits是可以用的，demo已经跑通，但是在Qt下，始终是“error: undefined reference to...”的问题，无论是手动添加库还是从工程中选择，都是这样的问题。通过VS可以知道，库是没有问题的，那么问题可能还是出在Qt调用静态库上。
    4.可以肯定问题出在静态库上，但什么原因，还不是很清楚，根据从网上找到的只言片语，有可能是因为生成CCfits库时的平台类型和Qt中mingw编译器的平台类型不符，导致库没有被识别出来。比较了一下自己在VS中建的静态库工程和CCfits经过CMake之后生成的工程，自己建的工程默认的解决方案平台是x86，而CCfits经过CMake之后自动生成的工程的解决方案平台是win32，除此之外，也没有别的差别，所以有可能是这个原因。
    5.自己写了个小测试，在VS中生成了一个静态库，在Qt中调用，发现也是同样的问题，而在VS中调用是没有问题的，这说明是Qt在调用静态库时的使用方法上出现了问题，而不是库本身出了问题。
    6.用同样的方法，生成动态库、调用动态库都是没问题的，就是静态库有问题，看来需要研究一下Qt调用VS静态库究竟有什么隐藏的问题。
    7.自己用Qt写了个静态库，生成的静态库是.a格式的，而不是像VS那样是.lib格式的，用Qt调用Qt生成的静态库是没有问题的。
    8.不再使用CCfits的静态库，改为使用源代码进行编译，但是cfitsio仍旧使用的是动态库，cfitsio也有源码，但是是用C写的，在使用时又牵涉到了令人头疼的字符串编码问题，因此暂时还是使用它的动态库吧，幸好它的动态库也是可用的。通过这种方式，今天下午终于编译通过，可以生成fits文件。程序位于：E:\MyProjects\Qt5.8.0_minGW530\CCFitsTest3\

2017-6-5

Done:
    1.再次学习Planetary-Imager，学习CMakeLists.txt的用法，学习开源软件的调试方法。
    2.CCFits可以读写FITS文件


2017-6-2

Todo:
    1.帧率使用当前帧率
    2.记录视频时，如果数据量太大，记不过来时需要做丢帧处理

Done:
    1.信息显示不能再在UserDrawingLayer上做了，UserDrawingLayer为了做ROI方框，其位置和尺寸必须与ImageShowWidget相一致，当图像大于显示区域时，将使用滚动条，但是对于信息显示，其位置和大小要与显示区域相一致，不管滚动条怎么调整，信息显示都不能被遮住，因此需要一个新图层，用来显示信息。根据这个思路对界面进行了一些改造，添加了ShowWidget层，ImageShowScrollArea和infoShowWidget重叠放置于ShowWidget层，但是不知什么原因，ImageShowScrollArea的滚动条失灵了，没有找到解决方法，所以暂时先恢复成原来的样子。
    2.仍旧在UserDrawingLayer上实现提示信息显示，后面需要一个较大的改动，将UI中的每一部分都分级叠加起来。
    3.显示记录文件的信息。
    4.记录视频时采用当前的瞬时帧率

2017-6-1

Todo:
    1.图片支持FIT格式
    2.记录视频时的帧率，根据当时的帧率进行设置，开始记录后，不允许调节ROI、图像空间、曝光时间(会影响帧率)等参数
    3.为防止乱点，应对按钮的使能情况做限制，记录静态图像时，点击记录之后，使按钮变灰，直到接到图像保存完成的事件，记录视频时，点击记录后，立即将按钮变为stop按钮，如果出现记录失败的情况，需要将按钮自动变回record按钮，点击停止后，使按钮变灰，直到接到视频记录完成的事件。
    4.记录完成后，应在界面上显示记录已完成及文件路径和文件名等信息。

Done:
    1.将HistogramShow设置为子窗口(SubWindow)，当主窗口关闭时，它也可以自动关闭。
    2.测试mp4格式，发现有时间有关系，如果记录的时间短，只有几秒，文件就播放不出来，如果记录的时间长一些，文件就是好的，可以播放。
    3.记录时的事件(开始、停止、出错)与界面的逻辑关系

2017-5-31

Memo:
    1.OpenCL(Open Computing Language)，面向异构系统、通用目的、并行编程，提供了基于任务分割和数据分割的并行计算机制，扩展了GPU用于图形生成之外的能力。
    2.OpenCL与CUDA，像是DirectX与OpenGL的关系。共同的目标都是通用并行计算，CUDA只能在NVIDIA的GPU上跑，OpenCL是忽略硬件的差异，CUDA的开发套件、库都比较成熟，OpenCL只有AMD的驱动相对成熟，CUDA使用C进行封装，使得对硬件了解不多也可以轻松上手，OpenCL則是針對硬件的應用程序開發接口，它能給程序員更多對硬件的控制權，但上手會較難一些。

Done:
    1.写电子邮件给Marco Gulino，咨询PlanetaryImager如何编译成.pro及调试的问题。
    2.添加对保存为TIF文件的支持。
    3.了解OpenCL与CUDA
    4.直方图窗口关闭通知。
    5.直方图可以显示R、G、B三条曲线

2017-5-27

Todo:
    1.查找记录成MP4格式时的问题
    2.通过返回值判断记录是否成功，函数的返回值需要补充一下
    3.直方图显示的很多细节还需要处理
    4.测试avi记录超过4G时有没有问题-------------------------------------------------------------------------------------

Done:
    1.测试封装C静态链接库功能
    2.将FFMpegVideoRecorder创建成静态库
    3.编译成静态库之后，却发现在Qt中依然不行，各种函数找不到，到处都是error: undefined reference to `avcodec_find_encoder'这样的错误。
    4.使用封装成静态库的方法依旧不行，还是继续使用昨天封装的函数进行调试
    5.av_ts2str和av_ts2timestr是timestamp.h中的宏，在编译到timestamp.h的时候，会报出找不到PRId64宏的错误，通过在VS中查看得知，PRId64宏是在inttypes.h中定义的(timestamp.h包含了common.h，common.h又包含了inttypes.h)，通过对比VS和QT中的inttypes.h后发现，VS调用的inttypes.h位于C:\Program Files (x86)\Windows Kits\10\Include\10.0.10240.0\ucrt路径下，而Qt的位于D:\Qt\Qt5.8.0_minGW530\Tools\mingw530_32\i686-w64-mingw32\include路径下，这两个文件的内容也不相同，VS中直接定义了#define PRId64       "lld"，而Qt中是在#if !defined(__cplusplus) || defined(__STDC_FORMAT_MACROS)下定义的，由于是C++程序，所以!defined(__cplusplus)为false，而__STDC_FORMAT_MACROS宏也没有被定义，所以这个if就没有被执行。通过查找资料可知，#define __STDC_FORMAT_MACROS这个宏是给C用的，C++如果要用，需要显式定义，手动添加#define __STDC_FORMAT_MACROS，再次编译，编译就通过了。(资料来源：http://blog.csdn.net/sukhoi27smk/article/details/38020425、http://blog.csdn.net/littlefang/article/details/8251668、http://blog.csdn.net/zhuweigangzwg/article/details/49799693，百度搜索__STDC_FORMAT_MACROS可得)
    6.Qt中的已经编译好，可以记录视频，但是MP4格式还有点问题，无法打开
    7.添加直方图显示控件
    8.实现对直方图显示控件的调用，大致实现了直方图，但还有很多细节需要处理

2017-5-26

Done:
    1.不再使用writeVideoData中的while循环来控制文件的完成，而是通过外部的for循环来控制。
    2.功能已经实现，但是放到Qt中之后，出现了各种问题，而且错误项都是出在ffmpeg自己的头文件中的，无法解决。现打算先在VS中封装成dll，然后再由Qt调用。
    3.测试封装C动态链接库功能

2017-5-25

Done:
    1.初步了解了YUV的格式及YUV的压缩格式，YUV420是其中的一种压缩格式，需要了解YUV420的压缩原理，才能知道怎么由RGB转换成YUV420；
    2.图像宽度的对齐，看来无论哪种图像格式，都免不了由对齐这一说，32位对齐可能是用地较多的，对于YUV来说，不但要计算Y的对齐值，还要计算U和V的对齐值，所以还是需要很小心的；
    3.程序已经可以将RGB24的数据转换成YUV420格式，生成的图像文件也是正确的。
    4.把数据作为参数传进去，图像数据使用外部传入的数据


2017-5-24

Todo:
    1.在线程中实现将数据保存成视频
    2.国际化(多语言支持)------------------------------------------------------------------------------------------------
    3.由于生成的文件太大，而且不能保存成mp4，因此还是需要再次看看muxing程序，仍旧需要在muxing上入手

Done:
    1.在数据记录线程类DataRecordThread中添加对VideoRecorder的调用。
    2.在 MainCtrl中添加对 DataRecordThread的调用，在UI中添加对记录视频功能的调用。
    3.两处问题导致数据无法正确记录和显示出来：(1).recordVideoContinuous函数中忘记了加start()，导致线程退出后无法再次启动；(2).编码器的格式需要传递AV_CODEC_ID_RAWVIDEO，这个还不明白是什么回事。
    4.这样可以记录数据了，但是数据怎么那么大呢，十几秒钟就上G了，而且不能保存成mp4格式，如果文件后缀是mp4就会崩溃。

2017-5-23

Done:
    1.周会
    2.将FFMpeg视频记录代码移至程序中

本周计划：
    1.完成记录视频功能，支持mp4和avi(注意超过4G时的情况)
    2.完成直方图功能
    3.图片增加支持FIT、TIF
    4.了解OpenCL和CUDA
    5.向Planetary-Imager作者咨询建立工程和调试事宜

2017-5-22

Memo:
    1.视频帧写入流程：write_video_frame-->get_video_frame-->av_init_packet-->avcodec_encode_video2-->write_frame
    2.muxing初始化流程：
            av_register_all
            -->avformat_alloc_output_context2
            -->add_stream
            -->open_video
            -->av_dump_format
            -->avio_open
    3.zwaviwriter初始化流程
            av_register_all
            -->avformat_alloc_output_context2
            -->av_init_packet
            -->add_vidio_stream
            -->avio_open

Todo:
    1.对muxing.c程序进行封装，使其可以自由设置格式和自定义数据。

2017-5-19

Done:
    1.调通FFMpeg的示例程序muxing.c，可以运行和根据自定义数据生成视频数据，但里面的数据和格式都是写死的，后面需要进行改造

2017-5-18

Todo:
    1.cuda、OpenCL

Memo:
    1.在Ubuntu下，终于把Planetary Imager编译通过，可以生成可执行文件，可执行文件也可以打开。但还有两个问题，一是不知道怎么生成Qt的.pro文件，无法进行调试，二是打开可执行文件后的界面，和源代码中的怎么有点不一样，例如，recording panel这个界面，可执行文件中运行后的record界面和程序中的recordingpanel.ui就不太一样。
    2.安装Linux下的INDI驱动时始终安装不成功，安装是按照官网中给出的链接http://indilib.org/download/ubuntu.html进行的，但运行sudo apt-get install indi-full时，提示说有很多的依赖项都没有装，列出了很多，都不认识，也不知道怎么装，因此，相机一直识别不出来。
    3.根据recordingpanel.ui中的索引，一步步追踪到记录视频数据是在LocalSaveImages::startRecording(Imager *imager)中做的，但是函数中的代码却看不懂。

2017-5-16

Memo:
    1.关闭了445、135端口，参考：http://www.pc6.com/infoview/Article_115461.html

2017-5-15

Todo:
    1.在Linux上编译Planetary-Imager
    2.学习如何使用FFMpeg记录视频数据
    3.如果Planetary-Imager编译通过，分析其所使用的记录视频的方法

2017-5-11

Done:
    1.查看整理SharpCap的实时叠加功能

2017-5-10

Done:
    1.查看LodestarLive的资料

Memo:
    1.在研究实时叠加时，把后期处理软件的离线叠加也考虑进来
    2.编译Planetary-Imager：昨天设置了OpenCV之后，又出现了找不到libusb包的情况(No package 'libusb-1.0' found)，今天下载了libusb-1.0的包，包括release的和源码，都试过了，始终报相同的错误，终无法解决。现决定放弃在windows编译，转而在Linux上进行编译。

2017-5-9

Todo:
    针对实时叠加技术：
    1.整理现有软件中的实时叠加功能，整理出它们的子功能及呈现方式，分析它们的实现方法。
    2.根据别人软件中的功能，思考我们需要重点关注的功能。
    3.实现这些功能需要的技术点，哪些是可以实现的或已经实现了的，哪些是还不知道怎么实现的，有哪些难点

    针对记录视频：
    1.分析开源软件planetary_imager中是怎么实现的
    2.测试如何用FFMpeg来实现
    3.比较用FFMpeg和OpenCV实现哪种更有利

2017-5-5

Todo:
    1.资料准备 实时叠加

Memo:
    1.以牛顿名字命名的望远镜：newtonian
    2.绿豆VPN 
    86676626@qq.com
    ZWOPTICAL
    Chrome插件：F:\Software\上网软件\绿豆VPN\Chrome插件

2017-5-4

Todo:
    1.保存成图片或视频
    2.实时叠加
    3.所有的QEventLoop都要加上一个定时退出
    4.直方图

2017-5-2

Todo:
    1.开始使用QSS对进行进行美化。

Memo:
    1.Bin功能，调用SDK中的ASISetROIFormat实现，但在设置Bin2时，最大化状态下设置总是失败，而在ROI状态下有时可以成功，有时会失败。
    测试ASISetROIFormat发现，当bin = 2时，ROI的宽度和高度必须小于总宽度和高度的一半，否则设置就会出错。
    找到了正确设置Bin的方法，当要设置的Bin值不为1时，除了要设置Bin的值，还需要将初始位置、ROI矩形大小都根据原来的Bin和新设置的Bin进行调整。

2017-4-20

Memo:
    SharpCap的功能：
    1.Color Space : MONO8、RAW8、RAW16、RGB24
    2.ROI
    3.Binning
    4.图像或视频输出格式
    5.Debayer
    6.曝光时间
    7.Gain
    8.Gamma
    9.Brightness
    10.White Bal

Todo:
    1.配置好OS X虚拟机、配置好Linux虚拟机
    2.查看Android版本有哪些功能，PC版本相应添加
    3.与杨楠一起讨论UI设计
    4.查找Qt在不同平台下分别编译的方法

2017-4-19

Memo:
    1.程序在Mac OS X下的运行
    2.程序在Mac Windows 10下的运行

2017-4-17

Memo:
    1.实现了显示图像帧频及帧数

2017-4-14

Todo:
    1.完成对类单例模式的改造。
    2.完成对ROI的实现，包括设置ROI和恢复最大值以及多级ROI

2017-4-12

Memo:
    1.AsiSdkCall中，在构造函数中增加参数来传递相机编号，其他函数都不再使用相机编号参数，这个类设计成只支持一个相机的，如果使用多个相机，new多个本类。

2017-4-11

Memo:
    1.ROI框选矩形的使能与不使能
    2.修复滚动条不显示的问题

2017-4-10

Memo:
    1.开始实现ROI

2017-3-30

Done:
    1.调用SDK
    2.Qt绘制自定义数据

2017-3-29

Memo:
    1.初步学习OpenGL，然后在Qt中连接SDK，获取图像数据，首先使用Qt的图像处理方式显示图像，然后再继续学习OpenGL，用OpenGL的方式显示图像，并比较在显示效果和性能上的差别。

2017-3-28

Memo:
    1.初步学习了在Qt中使用OpenGL绘制简单图像的方法，简单了解了QGLWidget、QOpenGLWidget和QOpenGLWindow，后面在开发程序时主要使用QOpenGLWidget。

2017-3-27

Memo:
    1.从Qt5.4开始，QOpenGLWidget替代了原来的QGLWidget以及QQuickWidget中相应部分。
    2.可以通过QOpenGLWindow很方便地将OpenGL的内容绘制到QWindow上。