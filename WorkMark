2017-6-1

Done:
    1.将HistogramShow设置为子窗口(SubWindow)，当主窗口关闭时，它也可以自动关闭。

2017-5-31

Memo:
    1.OpenCL(Open Computing Language)，面向异构系统、通用目的、并行编程，提供了基于任务分割和数据分割的并行计算机制，扩展了GPU用于图形生成之外的能力。
    2.OpenCL与CUDA，像是DirectX与OpenGL的关系。共同的目标都是通用并行计算，CUDA只能在NVIDIA的GPU上跑，OpenCL是忽略硬件的差异，CUDA的开发套件、库都比较成熟，OpenCL只有AMD的驱动相对成熟，CUDA使用C进行封装，使得对硬件了解不多也可以轻松上手，OpenCL則是針對硬件的應用程序開發接口，它能給程序員更多對硬件的控制權，但上手會較難一些。

Done:
    1.写电子邮件给Marco Gulino，咨询PlanetaryImager如何编译成.pro及调试的问题。
    2.添加对保存为TIF文件的支持。
    3.了解OpenCL与CUDA
    4.直方图窗口关闭通知。
    5.直方图可以显示R、G、B三条曲线

2017-5-27

Todo:
    1.查找记录成MP4格式时的问题-----------------------------------------------------------------------------------------
    2.通过返回值判断记录是否成功，函数的返回值需要补充一下
    3.直方图显示的很多细节还需要处理------------------------------------------------------------------------------------

Done:
    1.测试封装C静态链接库功能
    2.将FFMpegVideoRecorder创建成静态库
    3.编译成静态库之后，却发现在Qt中依然不行，各种函数找不到，到处都是error: undefined reference to `avcodec_find_encoder'这样的错误。
    4.使用封装成静态库的方法依旧不行，还是继续使用昨天封装的函数进行调试
    5.av_ts2str和av_ts2timestr是timestamp.h中的宏，在编译到timestamp.h的时候，会报出找不到PRId64宏的错误，通过在VS中查看得知，PRId64宏是在inttypes.h中定义的(timestamp.h包含了common.h，common.h又包含了inttypes.h)，通过对比VS和QT中的inttypes.h后发现，VS调用的inttypes.h位于C:\Program Files (x86)\Windows Kits\10\Include\10.0.10240.0\ucrt路径下，而Qt的位于D:\Qt\Qt5.8.0_minGW530\Tools\mingw530_32\i686-w64-mingw32\include路径下，这两个文件的内容也不相同，VS中直接定义了#define PRId64       "lld"，而Qt中是在#if !defined(__cplusplus) || defined(__STDC_FORMAT_MACROS)下定义的，由于是C++程序，所以!defined(__cplusplus)为false，而__STDC_FORMAT_MACROS宏也没有被定义，所以这个if就没有被执行。通过查找资料可知，#define __STDC_FORMAT_MACROS这个宏是给C用的，C++如果要用，需要显式定义，手动添加#define __STDC_FORMAT_MACROS，再次编译，编译就通过了。(资料来源：http://blog.csdn.net/sukhoi27smk/article/details/38020425、http://blog.csdn.net/littlefang/article/details/8251668、http://blog.csdn.net/zhuweigangzwg/article/details/49799693，百度搜索__STDC_FORMAT_MACROS可得)
    6.Qt中的已经编译好，可以记录视频，但是MP4格式还有点问题，无法打开
    7.添加直方图显示控件
    8.实现对直方图显示控件的调用，大致实现了直方图，但还有很多细节需要处理

2017-5-26

Done:
    1.不再使用writeVideoData中的while循环来控制文件的完成，而是通过外部的for循环来控制。
    2.功能已经实现，但是放到Qt中之后，出现了各种问题，而且错误项都是出在ffmpeg自己的头文件中的，无法解决。现打算先在VS中封装成dll，然后再由Qt调用。
    3.测试封装C动态链接库功能

2017-5-25

Done:
    1.初步了解了YUV的格式及YUV的压缩格式，YUV420是其中的一种压缩格式，需要了解YUV420的压缩原理，才能知道怎么由RGB转换成YUV420；
    2.图像宽度的对齐，看来无论哪种图像格式，都免不了由对齐这一说，32位对齐可能是用地较多的，对于YUV来说，不但要计算Y的对齐值，还要计算U和V的对齐值，所以还是需要很小心的；
    3.程序已经可以将RGB24的数据转换成YUV420格式，生成的图像文件也是正确的。
    4.把数据作为参数传进去，图像数据使用外部传入的数据


2017-5-24

Todo:
    1.在线程中实现将数据保存成视频
    2.国际化(多语言支持)------------------------------------------------------------------------------------------------
    3.由于生成的文件太大，而且不能保存成mp4，因此还是需要再次看看muxing程序，仍旧需要在muxing上入手

Done:
    1.在数据记录线程类DataRecordThread中添加对VideoRecorder的调用。
    2.在 MainCtrl中添加对 DataRecordThread的调用，在UI中添加对记录视频功能的调用。
    3.两处问题导致数据无法正确记录和显示出来：(1).recordVideoContinuous函数中忘记了加start()，导致线程退出后无法再次启动；(2).编码器的格式需要传递AV_CODEC_ID_RAWVIDEO，这个还不明白是什么回事。
    4.这样可以记录数据了，但是数据怎么那么大呢，十几秒钟就上G了，而且不能保存成mp4格式，如果文件后缀是mp4就会崩溃。

2017-5-23

Done:
    1.周会
    2.将FFMpeg视频记录代码移至程序中

本周计划：
    1.完成记录视频功能，支持mp4和avi(注意超过4G时的情况)----------------------------------------------------------------
    2.完成直方图功能----------------------------------------------------------------------------------------------------
    3.图片增加支持FIT、TIF----------------------------------------------------------------------------------------------
    4.了解OpenCL和CUDA--------------------------------------------------------------------------------------------------
    5.向Planetary-Imager作者咨询建立工程和调试事宜----------------------------------------------------------------------

2017-5-22

Memo:
    1.视频帧写入流程：write_video_frame-->get_video_frame-->av_init_packet-->avcodec_encode_video2-->write_frame
    2.muxing初始化流程：
            av_register_all
            -->avformat_alloc_output_context2
            -->add_stream
            -->open_video
            -->av_dump_format
            -->avio_open
    3.zwaviwriter初始化流程
            av_register_all
            -->avformat_alloc_output_context2
            -->av_init_packet
            -->add_vidio_stream
            -->avio_open

Todo:
    1.对muxing.c程序进行封装，使其可以自由设置格式和自定义数据。--------------------------------------------------------

2017-5-19

Done:
    1.调通FFMpeg的示例程序muxing.c，可以运行和根据自定义数据生成视频数据，但里面的数据和格式都是写死的，后面需要进行改造

2017-5-18

Todo:
    1.cuda、OpenCL

Memo:
    1.在Ubuntu下，终于把Planetary Imager编译通过，可以生成可执行文件，可执行文件也可以打开。但还有两个问题，一是不知道怎么生成Qt的.pro文件，无法进行调试，二是打开可执行文件后的界面，和源代码中的怎么有点不一样，例如，recording panel这个界面，可执行文件中运行后的record界面和程序中的recordingpanel.ui就不太一样。
    2.安装Linux下的INDI驱动时始终安装不成功，安装是按照官网中给出的链接http://indilib.org/download/ubuntu.html进行的，但运行sudo apt-get install indi-full时，提示说有很多的依赖项都没有装，列出了很多，都不认识，也不知道怎么装，因此，相机一直识别不出来。
    3.根据recordingpanel.ui中的索引，一步步追踪到记录视频数据是在LocalSaveImages::startRecording(Imager *imager)中做的，但是函数中的代码却看不懂。

2017-5-16

Memo:
    1.关闭了445、135端口，参考：http://www.pc6.com/infoview/Article_115461.html

2017-5-15

Todo:
    1.在Linux上编译Planetary-Imager-------------------------------------------------------------------------------------
    2.学习如何使用FFMpeg记录视频数据------------------------------------------------------------------------------------
    3.如果Planetary-Imager编译通过，分析其所使用的记录视频的方法--------------------------------------------------------

2017-5-11

Done:
    1.查看整理SharpCap的实时叠加功能

2017-5-10

Done:
    1.查看LodestarLive的资料

Memo:
    1.在研究实时叠加时，把后期处理软件的离线叠加也考虑进来
    2.编译Planetary-Imager：昨天设置了OpenCV之后，又出现了找不到libusb包的情况(No package 'libusb-1.0' found)，今天下载了libusb-1.0的包，包括release的和源码，都试过了，始终报相同的错误，终无法解决。现决定放弃在windows编译，转而在Linux上进行编译。

2017-5-9

Todo:
    针对实时叠加技术：
    1.整理现有软件中的实时叠加功能，整理出它们的子功能及呈现方式，分析它们的实现方法。
    2.根据别人软件中的功能，思考我们需要重点关注的功能。
    3.实现这些功能需要的技术点，哪些是可以实现的或已经实现了的，哪些是还不知道怎么实现的，有哪些难点

    针对记录视频：
    1.分析开源软件planetary_imager中是怎么实现的
    2.测试如何用FFMpeg来实现
    3.比较用FFMpeg和OpenCV实现哪种更有利--------------------------------------------------------------------------------

2017-5-5

Todo:
    1.资料准备 实时叠加

Memo:
    1.以牛顿名字命名的望远镜：newtonian
    2.绿豆VPN 
    86676626@qq.com
    ZWOPTICAL
    Chrome插件：F:\Software\上网软件\绿豆VPN\Chrome插件

2017-5-4

Todo:
    1.保存成图片或视频
    2.实时叠加
    3.所有的QEventLoop都要加上一个定时退出
    4.直方图------------------------------------------------------------------------------------------------------------

2017-5-2

Todo:
    1.开始使用QSS对进行进行美化。

Memo:
    1.Bin功能，调用SDK中的ASISetROIFormat实现，但在设置Bin2时，最大化状态下设置总是失败，而在ROI状态下有时可以成功，有时会失败。
    测试ASISetROIFormat发现，当bin = 2时，ROI的宽度和高度必须小于总宽度和高度的一半，否则设置就会出错。
    找到了正确设置Bin的方法，当要设置的Bin值不为1时，除了要设置Bin的值，还需要将初始位置、ROI矩形大小都根据原来的Bin和新设置的Bin进行调整。

2017-4-20

Memo:
    SharpCap的功能：
    1.Color Space : MONO8、RAW8、RAW16、RGB24
    2.ROI
    3.Binning
    4.图像或视频输出格式
    5.Debayer
    6.曝光时间
    7.Gain
    8.Gamma
    9.Brightness
    10.White Bal

Todo:
    1.配置好OS X虚拟机、配置好Linux虚拟机
    2.查看Android版本有哪些功能，PC版本相应添加
    3.与杨楠一起讨论UI设计
    4.查找Qt在不同平台下分别编译的方法

2017-4-19

Memo:
    1.程序在Mac OS X下的运行
    2.程序在Mac Windows 10下的运行

2017-4-17

Memo:
    1.实现了显示图像帧频及帧数

2017-4-14

Todo:
    1.完成对类单例模式的改造。
    2.完成对ROI的实现，包括设置ROI和恢复最大值以及多级ROI

2017-4-12

Memo:
    1.AsiSdkCall中，在构造函数中增加参数来传递相机编号，其他函数都不再使用相机编号参数，这个类设计成只支持一个相机的，如果使用多个相机，new多个本类。

2017-4-11

Memo:
    1.ROI框选矩形的使能与不使能
    2.修复滚动条不显示的问题

2017-4-10

Memo:
    1.开始实现ROI

2017-3-30

Done:
    1.调用SDK
    2.Qt绘制自定义数据

2017-3-29

Memo:
    1.初步学习OpenGL，然后在Qt中连接SDK，获取图像数据，首先使用Qt的图像处理方式显示图像，然后再继续学习OpenGL，用OpenGL的方式显示图像，并比较在显示效果和性能上的差别。

2017-3-28

Memo:
    1.初步学习了在Qt中使用OpenGL绘制简单图像的方法，简单了解了QGLWidget、QOpenGLWidget和QOpenGLWindow，后面在开发程序时主要使用QOpenGLWidget。

2017-3-27

Memo:
    1.从Qt5.4开始，QOpenGLWidget替代了原来的QGLWidget以及QQuickWidget中相应部分。
    2.可以通过QOpenGLWindow很方便地将OpenGL的内容绘制到QWindow上。